# -*- coding: utf-8 -*-
"""Copy of VBOTDA_PDNN-paper.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IrE4c67YfDLTuY3NaXdI-dXId_bfnJzt

# Probabilistic Deep Neural Network (PDNN) Processing of Vector Brillouin Optical Time Domain Analysis (VBOTDA) Data
"""

import scipy
import time
import pandas
import numpy as np
import os
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras import layers
from tensorflow.keras.utils import plot_model
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from matplotlib import cm
import matplotlib as mpl
from scipy.optimize import least_squares,leastsq,curve_fit
from tqdm import tqdm
import h5py
mpl.rcParams['savefig.dpi']=600
from sklearn.preprocessing import normalize
from numpy.random import normal,uniform
from sklearn import preprocessing as prepro
import os
import IPython
import tensorflow_probability as tfp
tfd = tfp.distributions
from numpy.random import seed
tf.random.set_seed(2)

"""## Utility Functions used in PDNN and Least-Squares Fitting
- <font color=blue>bgs_data_gen</font> : Function that generates noisy Brillouin gain spectrum (BGS) values for a given vector of frequency values, Brillouin frequency shift (BFS) $\nu_B$, Brillouin linewidth (FWHM) $w$ and noise amplitude $s$.
- <font color=blue>bps_data_gen</font> : Function that generates Brillouin phase spectrum (BPS) values for a given vector of frequency values, Brillouin frequency shift (BFS) $\nu_B$, Brillouin linewidth (FWHM) $w$ and noise amplitude $s$.
Clean BGS $g\left(\nu\right)$ and BPS $\phi\left(\nu\right)$ are simulated using a Lorentzian model:
\begin{align}
    g\left(\nu\right)&=g_0\frac{w^2}{4\left(\nu-\nu_b\right)^2+w^2} \label{gain}\\
    \phi\left(\nu\right)&=g_0\frac{2w\left(\nu-\nu_b\right)}{4\left(\nu-\nu_b\right)^2+w^2}  \label{phase}
\end{align}
A vector of $n$ noisy BGS in <font color=blue>bgs_data_gen</font> and noisy BPS in <font color=blue>bps_data_gen</font> are simulated using:
\begin{align}
    g_i&=g\left(\nu_i\right)+s\boldsymbol{\epsilon}_i, \quad \forall i=1,\cdots,n \\
    \phi_i&=\phi\left(\nu_i\right)+s\boldsymbol{\epsilon}_i, \quad \forall i=1,\cdots,n
\end{align}
where $\boldsymbol{\epsilon}_i \sim \mathcal{N}\left(0,I\right)$ is a standard normal random variable and the vector of frequency values $\left[\nu_1,\cdots,\nu_n\right]$ is sampled uniformly within a given range.
- <font color=blue>bgs_scale</font> : Function that scales BGS vector using \emph{Standard} normalization for better numerical treatment. Other options include \emph{Robust} and \emph{MinMax} normalization.
- <font color=blue>bps_scale</font> : Function that scales BPS vector using \emph{Standard} normalization for better numerical treatment. Other options include \emph{Robust} and \emph{MinMax} normalization.
- <font color=blue>LS_fit</font> : Function that estimates BFS, FWHM using nonlinear curve fitting and Lorentzian model. The argument \emph{mode} can be used to specify whether the input data is BGS or BPS.
- <font color=blue>batch_LS_fit</font> : Function that repeats the least squares fitting on a batch of BGS/BPS spectra.
- <font color=blue>file_LS_fit</font> : Function that repeats the least squares fitting on a BGS/BPS spectra in a given text file.
- <font color=blue>BOTDA_plotfn</font> : The mean $\mu$ and confidence intervals $\mu \pm 3\sigma$ of a given parameter are plotted along the fiber length.
"""

def bgs_data_gen(wvec,bgs_parms,noise=0.0):
    #wvec is freqvec- reference bfs value
    # fwhm is in MHZ
    n_w=len(wvec)
    bfs,fwhm = bgs_parms
    amp=1.0
    func=amp/(1+((wvec-bfs)/(fwhm/2))**2)
    func=func+noise*normal(0,1,n_w)
    return func

def bps_data_gen(wvec,bgs_parms,noise=0.0):
    #wvec is freqvec- reference bfs value
    # fwhm is in MHZ
    n_w=len(wvec)
    bfs,fwhm = bgs_parms
    amp=1.0
    func=amp*(wvec-bfs)*(fwhm/2)/((wvec-bfs)**2+(fwhm/2)**2)
    func=func+noise*normal(0,1,n_w)
    return func

def bgs_scale(yvec,scaling='Standard'):
    if scaling is 'Standard':
        scaler=prepro.StandardScaler()
    elif scaling is 'MinMax':
        scaler=prepro.MinMaxScaler()
    elif scaling is 'Robust':
        scaler=prepro.RobustScaler()
    else:
        raise ValueError()
    return scaler.fit_transform(yvec.reshape(len(yvec),1)).flatten()

def bps_scale(yvec,scaling='Standard'):
    if scaling is 'Standard':
        scaler=prepro.StandardScaler()
    elif scaling is 'MinMax':
        scaler=prepro.MinMaxScaler(feature_range=(-0.5,0.5))
    elif scaling is 'Robust':
        scaler=prepro.RobustScaler()
    else:
        raise ValueError()
    return scaler.fit_transform(yvec.reshape(len(yvec),1)).flatten()

def LS_fit(data,x0,mode='bgs'):
    xdata=data[:,0]
    ydataraw=data[:,1]
    if mode == 'bgs':
        ydata=bgs_scale(ydataraw,'MinMax')
        def fun(xdata,fpeak,fwhm):
            return bgs_data_gen(xdata,[fpeak,fwhm])
    elif mode == 'bps':
        ydata=bps_scale(ydataraw,'MinMax')
        def fun(xdata,fpeak,fwhm):
            return bps_data_gen(xdata,[fpeak,fwhm])
    else:
        raise ValueError()
    x,cov_x=curve_fit(fun, xdata,ydata, p0=x0,bounds=(np.array([0,5]), np.array([80,60])))
    x_err=[np.sqrt(cov_x[j,j]) for j in range(x.size)]
    return x,x_err

def batch_LS_fit(raw_data,wvec,x0,mode='bgs'):
    n_x=raw_data.shape[1]
    parmat=np.zeros((n_x,2))
    parerr=np.zeros((n_x,2))
    for i in tqdm(range(n_x)):
        data=np.column_stack([wvec,raw_data[:,i]])
        parmat[i,:],parerr[i,:]=LS_fit(data,x0,mode)
    return parmat, parerr

def file_LS_fit(file,wvec,x0,mode='bgs'):
    raw_data=np.loadtxt(file)
    parmat,parerr=batch_LS_fit(raw_data,wvec,x0,mode)
    return parmat, parerr

def BOTDA_plotfn(xvec,parmean,parstd,filename,
            figsize=(12,3),figfmt='svg',ylims=None):
    ylabels=['BFS Mean (MHz)','FWHM (MHz)']
    fig,ax=plt.subplots(1,2,figsize=figsize)
    for pind in range(2):
        ax[pind].plot(xvec,parmean[:,pind],'k-',label='predicted mean')
        ax[pind].set_xlabel('Fiber Length (km)')
        ax[pind].set_ylabel(ylabels[pind])
        ymin=parmean[:,pind] - 3*parstd[:,pind]
        ymax=parmean[:,pind] + 3*parstd[:,pind]
        ax[pind].fill_between(xvec,ymin.flatten(), ymax.flatten(),color='blue', alpha=0.25,label='99% confidence interval')
        ax[pind].legend(loc='lower right')
        ax[pind].set_title("$\sigma =$%5.3f"%(np.std(parmean[:,pind])))
        ax[pind].grid()
        if ylims is None:
            ax[pind].set_ylim([0.98*np.min(ymin),1.02*np.max(ymax)])
        else:
            ax[pind].set_ylim(ylims[pind])
    plt.tight_layout(w_pad=2.0)
    plt.savefig(filename,format=figfmt,dpi=600)

"""## Python Class Definition of VBOTDA_PDNN model
- <font color=blue> init </font> : Function that takes inputs necessary for PDNN model architecture, vector of frequency values and training parameters
- <font color=blue> data_batchgen </font> : Function that generates a batch dataset of BGS or BPS. The mode is BGS by default and can be modified by \emph{mode} argument to generate a BPS dataset
- <font color=blue> create_model </font> : Function that creates a DNN model with convolutional, pooling and dense layers.
- <font color=blue> train_model </font> : Function that trains the DNN model using a simulated dataset and maximum likelihood loss function
- <font color=blue>batch_predict</font> : Function that repeats the PDNN fitting on a batch of BGS/BPS spectra.
- <font color=blue>file_DNN_predict</font> : Function that repeats the PDNN fitting on a BGS/BPS spectra in a given text file.
"""

class VBOTDA_PDNN:
    def __init__(self, wvec,**kwargs):
        self.model='network has not been loaded'
        self.model_history='Network has not been trained'
        self.wvec=wvec
        n_channels=2
        self.n_out=1
        self.scaling='Standard'
        self.batch_size=100
        self.max_epochs=500
        if 'channels' in kwargs:
            n_channels=kwargs['channels']
        if 'outputs' in kwargs:
            self.n_out=kwargs['outputs']
        if 'scaler' in kwargs:
            self.scaling=kwargs['scaler']
        if 'batch_size' in kwargs:
            self.batch_size=kwargs['batch_size']
        if 'max_epochs' in kwargs:
            self.max_epochs=kwargs['max_epochs']
        self.input_shape=(len(wvec),n_channels)

    def data_batchgen(self,parmat,mode='bgs'):
        n_w,n_c=self.input_shape
        N=parmat.shape[0]
        func_parms = parmat[:,0:self.n_out]
        func_results= np.zeros(shape =(N, n_w,n_c))
        for i in range(N):
            func_results[i,:,0] = self.wvec
            if mode == 'bgs':
                bgsvec=bgs_data_gen(self.wvec,parmat[i,:2],noise=1/parmat[i,2])
                func_results[i,:,1] = bgs_scale(bgsvec,scaling=self.scaling)
            elif mode == 'bps':
                bpsvec=bps_data_gen(self.wvec,parmat[i,:2],noise=1/parmat[i,2])
                func_results[i,:,1] = bps_scale(bpsvec,scaling=self.scaling)
        return func_results, func_parms


    def create_model(self):
        inputs = tf.keras.Input(shape=self.input_shape)
        x = inputs
        x = layers.Conv1D(64, 15,activation='relu',padding='same')(x)
        x = layers.MaxPool1D(3)(x)
        x = layers.Conv1D(64, 5,activation='relu',padding='same')(x)
        x = layers.MaxPool1D(3)(x)
        x = layers.Flatten()(x)
        units_vec=[32]
        for ind in range(len(units_vec)):
            x= layers.Dense(units=units_vec[ind],activation='relu',
                           bias_regularizer='l2',kernel_regularizer='l2')(x)
        if self.n_out is 2:
            x= layers.Dense(4,activation='linear')(x)
            outputs=tfp.layers.DistributionLambda(lambda t: tfd.Independent(tfd.Normal(loc=t[..., :2],
                     scale=1e-5 + tf.math.softplus(0.1* t[..., 2:])),reinterpreted_batch_ndims=1))(x)
        elif self.n_out is 1:
            x= layers.Dense(2,activation='linear')(x)
            outputs= tfp.layers.DistributionLambda(lambda t: tfd.Normal(loc=t[...,:1],
                               scale=1e-5+tf.math.softplus(0.1*t[..., 1:]))) (x)
        else:
            raise ValueError()
        self.model = tf.keras.Model(inputs, outputs)

    def train_model(self,N=50000,X=None,y=None,**kwargs):
        if X is None:
            if 'minvals' in kwargs:
                par_min= kwargs['minvals']
            else :
                par_min=(10.0,5.0,5.0)
            if 'maxvals' in kwargs:
                par_max= kwargs['maxvals']
            else :
                par_max=(55.0,40.0,18.0)
            if 'mode' in kwargs:
                mode=kwargs['mode']
            parmat=np.random.uniform(par_min,par_max,(N,3))
            X,y=self.data_batchgen(parmat,mode)

        negloglik = lambda y, p_y: -p_y.log_prob(y)
        cb_ES = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01,
                                        patience=10, restore_best_weights=True)
        cb_LR=tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.7,
                    patience=3, verbose=0, mode='auto',min_delta=0.001, min_lr=0.001)
        self.model.compile(optimizer=tf.keras.optimizers.Adam(0.005),loss=negloglik)
        self.model_history=self.model.fit(X,y, validation_split=0.3,batch_size=self.batch_size,
                    epochs=self.max_epochs, callbacks=[cb_LR,cb_ES],shuffle=True,verbose=2)
        #self.model.save(model_file_name)

    def batch_predict(self,data,mode='bgs'):
        n_w,n_c=self.input_shape
        n_out=self.n_out
        N=data.shape[1]
        inputs=np.zeros((N,n_w,n_c))
        for i in range(N):
            inputs[i,:,0]=self.wvec
            if mode =='bgs':
                inputs[i,:,1]=bgs_scale(data[:,i],scaling=self.scaling)
            elif mode == 'bps':
                inputs[i,:,1]=bps_scale(data[:,i],scaling=self.scaling)
            else:
                raise ValueError()
        pred_rv=self.model(inputs)
        par_mean=pred_rv.mean().numpy()
        par_std=pred_rv.stddev().numpy()
        return par_mean, par_std

    def file_DNN_predict(self,file,mode='bgs'):
        raw_data=np.loadtxt(file)
        par_mean,par_std=self.batch_predict(raw_data,mode)
        return par_mean, par_std

"""## Train VBOTDA_PDNN Model on Simulated Data"""

wvec=1000*(np.arange(10.800,10.9001,0.002)-10.800)
model_dict={'channels':2,'outputs':2, 'batch_size':100, 'scaler':'Standard','mode':'bgs'}
A1=VBOTDA_PDNN(wvec,**model_dict)
A1.create_model()
print(A1.model.summary())
A1.train_model(N=int(50e3),**model_dict)

"""## Test VBOTDA_PDNN Model on Gain or Phase Dataset"""

import time
direc=os.getcwd()
data_direc=direc+'/Data/'
model_direc=direc+'/'
file='Gain1.txt'
wvec=1000*(np.arange(10.800,10.9001,0.002)-10.800)
stdlist=np.zeros(1)
meanlist=np.zeros(1)
LS_resdict={'par_mean':[], 'par_std': []}
NN_resdict={'par_mean':[], 'par_std': []}
raw_data=np.loadtxt(data_direc+file,delimiter=',')
raw_data_red=raw_data[10:61,1:]
start = time.time()
par_mean,par_std=A1.batch_predict(raw_data_red)
end = time.time()
print(end - start)

NN_resdict['par_mean'].append(par_mean)
NN_resdict['par_std'].append(par_std)
xvec=np.linspace(0,25,par_mean.shape[0])
plotfilename='Gain_prob_var2_NN_v3.png'
BOTDA_plotfn(xvec,par_mean,par_std,plotfilename,
            figsize=(9,3),figfmt='png',ylims=None)

x0=[30,35]
start = time.time()
LS_parmat,LS_err=batch_LS_fit(raw_data_red,wvec,x0,mode='bgs')
end = time.time()
print(end - start)
LS_resdict['par_mean'].append(LS_parmat)
LS_resdict['par_std'].append(LS_err)
plotfilename='Gain_prob_var2_LS_v3.png'
xvec=np.linspace(0,25,LS_parmat.shape[0])
BOTDA_plotfn(xvec,LS_parmat,LS_err,plotfilename,
            figsize=(9,3),figfmt='png',ylims=None)